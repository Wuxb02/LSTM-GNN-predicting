"""
GNNæ¨¡å‹åŒ…è£…å™¨

ä»æ··åˆLSTM-GNNæ¨¡å‹ä¸­æå–çº¯GNNéƒ¨åˆ†,ç”¨äºGNNExplaineråˆ†æ

å…³é”®è®¾è®¡:
- GATWrapper: æå–GAT_LSTMçš„GATå±‚å’Œè¾“å‡ºå±‚
- GSAGEWrapper: æå–GSAGE_LSTMçš„SAGEå±‚å’Œè¾“å‡ºå±‚
- å…±äº«åŸæ¨¡å‹æƒé‡,æ— éœ€é‡æ–°è®­ç»ƒ
- è¾“å…¥: LSTMè¾“å‡ºç‰¹å¾ [num_nodes, hid_dim]
- è¾“å‡º: é¢„æµ‹å€¼ [num_nodes, pred_len]

ä½œè€…: GNNæ°”æ¸©é¢„æµ‹é¡¹ç›®
æ—¥æœŸ: 2025
"""

import torch
import torch.nn as nn


class GATWrapper(nn.Module):
    """
    GAT_LSTMæ¨¡å‹çš„GNNéƒ¨åˆ†åŒ…è£…å™¨

    ä»å®Œæ•´çš„GAT_LSTMæ¨¡å‹ä¸­æå–GATå›¾å·ç§¯å±‚å’ŒMLPè¾“å‡ºå±‚,
    ç”¨äºGNNExplaineråˆ†æç©ºé—´ä¾èµ–å…³ç³»

    Args:
        gat_lstm_model: å®Œæ•´çš„GAT_LSTMæ¨¡å‹å®ä¾‹

    è¾“å…¥: [num_nodes, hid_dim] - LSTMè¾“å‡ºç‰¹å¾
    è¾“å‡º: [num_nodes, pred_len] - é¢„æµ‹å€¼
    """

    def __init__(self, gat_lstm_model):
        super().__init__()
        # å¼•ç”¨åŸæ¨¡å‹çš„GATå±‚å’Œè¾“å‡ºå±‚(å…±äº«æƒé‡)
        self.GAT_layers = gat_lstm_model.GAT_layers
        self.nGAT_layer = gat_lstm_model.nGAT_layer
        self.element = gat_lstm_model.element

        # ä¿å­˜ç»´åº¦ä¿¡æ¯
        self.hid_dim = gat_lstm_model.hid_dim

        # æ£€æŸ¥æ¨¡å‹ä½¿ç”¨çš„è§£ç å™¨ç±»å‹
        self.use_recurrent_decoder = gat_lstm_model.use_recurrent_decoder

        if self.use_recurrent_decoder:
            # å¾ªç¯è§£ç å™¨æ¨¡å¼
            self.decoder_type = gat_lstm_model.decoder_type
            self.decoder_use_context = gat_lstm_model.decoder_use_context
            self.decoder_mlp = gat_lstm_model.decoder_mlp if hasattr(gat_lstm_model, 'decoder_mlp') else None
            self.decoder = gat_lstm_model.decoder
            self.decoder_output_proj = gat_lstm_model.decoder_output_proj
            self.decoder_init_proj = gat_lstm_model.decoder_init_proj
            self.out_dim = gat_lstm_model.out_dim
        else:
            # MLPè¾“å‡ºå±‚æ¨¡å¼
            self.MLP_layers_out = gat_lstm_model.MLP_layers_out

    def train(self, mode=True):
        """
        è¦†ç›–train()æ–¹æ³•,ç¡®ä¿å¾ªç¯è§£ç å™¨åœ¨éœ€è¦æ¢¯åº¦æ—¶å¤„äºè®­ç»ƒæ¨¡å¼

        è¿™å¯¹äºGNNExplaineréå¸¸é‡è¦,å› ä¸ºcuDNN RNNåç«¯
        åªèƒ½åœ¨è®­ç»ƒæ¨¡å¼ä¸‹è¿›è¡Œåå‘ä¼ æ’­
        """
        super().train(mode)
        if self.use_recurrent_decoder:
            # å¼ºåˆ¶è§£ç å™¨è¿›å…¥è®­ç»ƒæ¨¡å¼ä»¥æ”¯æŒåå‘ä¼ æ’­
            self.decoder.train(mode)
            if self.decoder_mlp is not None:
                self.decoder_mlp.train(mode)
        return self

    def eval(self):
        """
        è¦†ç›–eval()æ–¹æ³•

        å½“æ¨¡å‹ä½¿ç”¨å¾ªç¯è§£ç å™¨æ—¶,æˆ‘ä»¬éœ€è¦ä¿æŒè§£ç å™¨åœ¨è®­ç»ƒæ¨¡å¼
        ä»¥æ”¯æŒGNNExplainerçš„åå‘ä¼ æ’­ã€‚è¿™æ˜¯ä¸€ä¸ªç‰¹æ®Šå¤„ç†,
        ä»…åœ¨å¯è§£é‡Šæ€§åˆ†ææ—¶ä½¿ç”¨ã€‚
        """
        # åªå°†GATå±‚è®¾ä¸ºevalæ¨¡å¼,ä½†ä¿æŒè§£ç å™¨ä¸ºè®­ç»ƒæ¨¡å¼
        if self.use_recurrent_decoder:
            # GATå±‚å¯ä»¥eval
            for layer in self.GAT_layers:
                layer.eval()
            # ä½†è§£ç å™¨å¿…é¡»ä¿æŒè®­ç»ƒæ¨¡å¼ä»¥æ”¯æŒcuDNNåå‘ä¼ æ’­
            self.decoder.train()
            if self.decoder_mlp is not None:
                self.decoder_mlp.train()
            # æŠ•å½±å±‚ä¹Ÿè®¾ä¸ºeval
            self.decoder_output_proj.eval()
            self.decoder_init_proj.eval()
        else:
            # æ ‡å‡†evalæ¨¡å¼
            super().eval()
        return self

    def forward(self, x, edge_index, edge_attr=None, return_attention=False):
        """
        å‰å‘ä¼ æ’­(ä»…GATéƒ¨åˆ†)

        Args:
            x: [num_nodes, hid_dim] LSTMè¾“å‡ºç‰¹å¾
            edge_index: [2, num_edges]
            edge_attr: è¾¹å±æ€§(GATv2Convä¸ä½¿ç”¨,ä¿ç•™æ¥å£ç»Ÿä¸€)
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡

        Returns:
            if return_attention:
                output: [num_nodes, pred_len]
                attention_weights_list: List[(edge_index, attention_weights)]
                    æ¯å±‚GATçš„æ³¨æ„åŠ›æƒé‡,å·²å¯¹å¤šå¤´å–å¹³å‡
            else:
                output: [num_nodes, pred_len]
        """
        attention_weights_list = []

        # GATå›¾å·ç§¯å±‚(å¤åˆ»åŸæ¨¡å‹é€»è¾‘)
        for i in range(self.nGAT_layer):
            base_idx = i * self.element

            # GATå·ç§¯
            if return_attention:
                # æå–æ³¨æ„åŠ›æƒé‡
                # GATv2Conv.forward(..., return_attention_weights=True)
                # è¿”å›: (Tensor, (edge_index, attention_weights))
                x, (attn_edge_index, attn_weights) = self.GAT_layers[base_idx](
                    x, edge_index, return_attention_weights=True
                )
                # attn_weights shape: [num_edges, num_heads]
                # å¯¹å¤šå¤´å–å¹³å‡
                attn_avg = attn_weights.mean(dim=1)  # [num_edges]
                attention_weights_list.append((attn_edge_index, attn_avg))
            else:
                x = self.GAT_layers[base_idx](x, edge_index)

            # åç»­å±‚(Linear, AF, BN?, Dropout?)
            for j in range(1, self.element):
                x = self.GAT_layers[base_idx + j](x)

        # è¾“å‡ºç”Ÿæˆ(æ ¹æ®è§£ç å™¨ç±»å‹)
        if self.use_recurrent_decoder:
            # ğŸ”‘ å¾ªç¯è§£ç å™¨ï¼šé€æ­¥ç”Ÿæˆé¢„æµ‹åºåˆ—
            outputs = []
            encoder_context = x  # [N, hid_dim]

            num_layers = self.decoder.num_layers
            if self.decoder_type == 'LSTM':
                h_0 = x.unsqueeze(0).repeat(num_layers, 1, 1)
                c_0 = torch.zeros_like(h_0)
                hidden = (h_0, c_0)
            else:
                hidden = x.unsqueeze(0).repeat(num_layers, 1, 1)

            prev_pred = self.decoder_init_proj(x)  # [N, 1]

            for t in range(self.out_dim):
                if self.decoder_use_context:
                    decoder_input = torch.cat(
                        [prev_pred, encoder_context], dim=1
                    )
                else:
                    decoder_input = prev_pred

                if self.decoder_mlp is not None:
                    decoder_input = self.decoder_mlp(decoder_input)

                decoder_input = decoder_input.unsqueeze(0)
                decoder_output, hidden = self.decoder(decoder_input, hidden)

                pred_t = self.decoder_output_proj(decoder_output.squeeze(0))
                outputs.append(pred_t)
                prev_pred = pred_t

            x = torch.cat(outputs, dim=1)  # [N, pred_len]
        else:
            # MLPè¾“å‡ºå±‚(åŸæœ‰æ–¹å¼)
            x = self.MLP_layers_out(x)

        if return_attention:
            return x, attention_weights_list
        return x

    @staticmethod
    def extract_lstm_features(full_model, input_data, edge_index, device):
        """
        ä»å®Œæ•´GAT_LSTMæ¨¡å‹æå–LSTMè¾“å‡ºç‰¹å¾

        Args:
            full_model: å®Œæ•´çš„GAT_LSTMæ¨¡å‹
            input_data: [num_nodes, hist_len, in_dim] åŸå§‹è¾“å…¥
            edge_index: [2, num_edges]
            device: 'cuda' or 'cpu'

        Returns:
            lstm_features: [num_nodes, hid_dim] LSTMè¾“å‡ºç‰¹å¾
        """
        full_model.eval()
        with torch.no_grad():
            # 1. è½¬æ¢ç»´åº¦
            x = input_data.permute(1, 0, 2)  # [hist_len, num_nodes, in_dim]

            # 2. MLPè¾“å…¥å±‚
            x = full_model.MLP_layers_in(x)  # [hist_len, num_nodes, hid_dim]

            # 3. LSTMæ—¶åºå»ºæ¨¡
            out, _ = full_model.lstm(x)
            x = out.contiguous()
            x = x[-1]  # å–æœ€åæ—¶é—´æ­¥ [num_nodes, hid_dim] æˆ– [num_nodes, 2*hid_dim]

            # 4. åŒå‘LSTMæŠ•å½±
            if full_model.lstm_bidirectional:
                x = full_model.lstm_fc(x)  # [num_nodes, hid_dim]

        return x.to(device)


class GSAGEWrapper(nn.Module):
    """
    GSAGE_LSTMæ¨¡å‹çš„GNNéƒ¨åˆ†åŒ…è£…å™¨

    ä»å®Œæ•´çš„GSAGE_LSTMæ¨¡å‹ä¸­æå–SAGEå›¾å·ç§¯å±‚å’ŒMLPè¾“å‡ºå±‚

    Args:
        gsage_lstm_model: å®Œæ•´çš„GSAGE_LSTMæ¨¡å‹å®ä¾‹

    è¾“å…¥: [num_nodes, hid_dim] - LSTMè¾“å‡ºç‰¹å¾
    è¾“å‡º: [num_nodes, pred_len] - é¢„æµ‹å€¼
    """

    def __init__(self, gsage_lstm_model):
        super().__init__()
        # å¼•ç”¨åŸæ¨¡å‹çš„SAGEå±‚å’Œè¾“å‡ºå±‚(å…±äº«æƒé‡)
        self.SAGE_layers = gsage_lstm_model.SAGE_layers
        self.MLP_layers_out = gsage_lstm_model.MLP_layers_out
        self.nSAGE_layer = gsage_lstm_model.nSAGE_layer
        self.element = gsage_lstm_model.element

        # ä¿å­˜ç»´åº¦ä¿¡æ¯
        self.hid_dim = gsage_lstm_model.hid_dim

    def forward(self, x, edge_index, edge_attr=None):
        """
        å‰å‘ä¼ æ’­(ä»…SAGEéƒ¨åˆ†)

        Args:
            x: [num_nodes, hid_dim] LSTMè¾“å‡ºç‰¹å¾
            edge_index: [2, num_edges]
            edge_attr: è¾¹å±æ€§(SAGEConvä¸ä½¿ç”¨,ä¿ç•™æ¥å£ç»Ÿä¸€)

        Returns:
            output: [num_nodes, pred_len]
        """
        # SAGEå›¾å·ç§¯å±‚(å¤åˆ»åŸæ¨¡å‹é€»è¾‘)
        for i in range(self.nSAGE_layer):
            base_idx = i * self.element
            # SAGEå·ç§¯
            x = self.SAGE_layers[base_idx](x, edge_index)
            # åç»­å±‚(AF, BN?, Dropout?)
            for j in range(1, self.element):
                x = self.SAGE_layers[base_idx + j](x)

        # MLPè¾“å‡ºå±‚
        x = self.MLP_layers_out(x)

        return x

    @staticmethod
    def extract_lstm_features(full_model, input_data, edge_index, device):
        """
        ä»å®Œæ•´GSAGE_LSTMæ¨¡å‹æå–LSTMè¾“å‡ºç‰¹å¾

        Args:
            full_model: å®Œæ•´çš„GSAGE_LSTMæ¨¡å‹
            input_data: [num_nodes, hist_len, in_dim] åŸå§‹è¾“å…¥
            edge_index: [2, num_edges]
            device: 'cuda' or 'cpu'

        Returns:
            lstm_features: [num_nodes, hid_dim] LSTMè¾“å‡ºç‰¹å¾
        """
        full_model.eval()
        with torch.no_grad():
            # 1. è½¬æ¢ç»´åº¦
            x = input_data.permute(1, 0, 2)  # [hist_len, num_nodes, in_dim]

            # 2. MLPè¾“å…¥å±‚
            x = full_model.MLP_layers_in(x)  # [hist_len, num_nodes, hid_dim]

            # 3. LSTMæ—¶åºå»ºæ¨¡
            out, _ = full_model.lstm(x)
            x = out.contiguous()
            x = x[-1]  # å–æœ€åæ—¶é—´æ­¥

            # 4. åŒå‘LSTMæŠ•å½±
            if full_model.lstm_bidirectional:
                x = full_model.lstm_fc(x)

        return x.to(device)


class GATSeparateEncoderWrapper(nn.Module):
    """
    GAT_SeparateEncoderæ¨¡å‹çš„GNNéƒ¨åˆ†åŒ…è£…å™¨

    ä»å®Œæ•´çš„GAT_SeparateEncoderæ¨¡å‹ä¸­æå–GATå›¾å·ç§¯å±‚å’Œè§£ç å™¨,
    ç”¨äºGNNExplaineråˆ†æç©ºé—´ä¾èµ–å…³ç³»

    Args:
        model: å®Œæ•´çš„GAT_SeparateEncoderæ¨¡å‹å®ä¾‹

    è¾“å…¥: [num_nodes, hid_dim] - ç¼–ç å™¨è¾“å‡ºç‰¹å¾
    è¾“å‡º: [num_nodes, pred_len] - é¢„æµ‹å€¼
    """

    def __init__(self, gat_separate_model):
        super().__init__()
        # å¼•ç”¨åŸæ¨¡å‹çš„GATå±‚å’Œè§£ç å™¨(å…±äº«æƒé‡)
        self.GAT_layers = gat_separate_model.GAT_layers
        self.nGAT_layer = gat_separate_model.nGAT_layer
        self.element = gat_separate_model.element

        # ä¿å­˜ç»´åº¦ä¿¡æ¯
        self.hid_dim = gat_separate_model.hid_dim

        # æ£€æŸ¥æ¨¡å‹ä½¿ç”¨çš„è§£ç å™¨ç±»å‹
        self.use_recurrent_decoder = gat_separate_model.use_recurrent_decoder

        if self.use_recurrent_decoder:
            # å¾ªç¯è§£ç å™¨æ¨¡å¼
            self.decoder_type = gat_separate_model.decoder_type
            self.decoder_use_context = gat_separate_model.decoder_use_context
            self.decoder_mlp = gat_separate_model.decoder_mlp if hasattr(gat_separate_model, 'decoder_mlp') else None
            self.decoder = gat_separate_model.decoder
            self.decoder_output_proj = gat_separate_model.decoder_output_proj
            self.decoder_init_proj = gat_separate_model.decoder_init_proj
            self.out_dim = gat_separate_model.out_dim
        else:
            # MLPè¾“å‡ºå±‚æ¨¡å¼
            self.MLP_layers_out = gat_separate_model.MLP_layers_out

    def train(self, mode=True):
        """è¦†ç›–train()æ–¹æ³•"""
        super().train(mode)
        if self.use_recurrent_decoder:
            self.decoder.train(mode)
            if self.decoder_mlp is not None:
                self.decoder_mlp.train(mode)
        return self

    def eval(self):
        """è¦†ç›–eval()æ–¹æ³•,ä¿æŒè§£ç å™¨è®­ç»ƒæ¨¡å¼ä»¥æ”¯æŒåå‘ä¼ æ’­"""
        if self.use_recurrent_decoder:
            for layer in self.GAT_layers:
                layer.eval()
            self.decoder.train()
            if self.decoder_mlp is not None:
                self.decoder_mlp.train()
            self.decoder_output_proj.eval()
            self.decoder_init_proj.eval()
        else:
            super().eval()
        return self

    def forward(self, x, edge_index, edge_attr=None, return_attention=False):
        """å‰å‘ä¼ æ’­(ä»…GATå’Œè§£ç å™¨éƒ¨åˆ†)"""
        attention_weights_list = []

        # GATå›¾å·ç§¯å±‚
        for i in range(self.nGAT_layer):
            base_idx = i * self.element

            if return_attention:
                x, (attn_edge_index, attn_weights) = self.GAT_layers[base_idx](
                    x, edge_index, return_attention_weights=True
                )
                attn_avg = attn_weights.mean(dim=1)
                attention_weights_list.append((attn_edge_index, attn_avg))
            else:
                x = self.GAT_layers[base_idx](x, edge_index)

            for j in range(1, self.element):
                x = self.GAT_layers[base_idx + j](x)

        # è¾“å‡ºç”Ÿæˆ
        if self.use_recurrent_decoder:
            outputs = []
            encoder_context = x

            num_layers = self.decoder.num_layers
            if self.decoder_type == 'LSTM':
                h_0 = x.unsqueeze(0).repeat(num_layers, 1, 1)
                c_0 = torch.zeros_like(h_0)
                hidden = (h_0, c_0)
            else:
                hidden = x.unsqueeze(0).repeat(num_layers, 1, 1)

            prev_pred = self.decoder_init_proj(x)

            for t in range(self.out_dim):
                if self.decoder_use_context:
                    decoder_input = torch.cat([prev_pred, encoder_context], dim=1)
                else:
                    decoder_input = prev_pred

                if self.decoder_mlp is not None:
                    decoder_input = self.decoder_mlp(decoder_input)

                decoder_input = decoder_input.unsqueeze(0)
                decoder_output, hidden = self.decoder(decoder_input, hidden)

                pred_t = self.decoder_output_proj(decoder_output.squeeze(0))
                outputs.append(pred_t)
                prev_pred = pred_t

            x = torch.cat(outputs, dim=1)
        else:
            x = self.MLP_layers_out(x)

        if return_attention:
            return x, attention_weights_list
        return x

    @staticmethod
    def extract_encoder_features(full_model, input_data, edge_index, device):
        """
        ä»å®Œæ•´GAT_SeparateEncoderæ¨¡å‹æå–ç¼–ç å™¨è¾“å‡ºç‰¹å¾

        æ”¯æŒ v2.0 å’Œ v3.0 ä¸¤ç§æ¶æ„:
        - v2.0: static_encoder + dynamic_encoder + fusion(static_emb, dynamic_emb)
        - v3.0: dynamic_encoder + fusion(static_features, dynamic_emb)
                fusionå†…éƒ¨åŒ…å«CrossAttentionFusionV2.static_encoder

        Args:
            full_model: å®Œæ•´çš„GAT_SeparateEncoderæ¨¡å‹
            input_data: [num_nodes, hist_len, in_dim] åŸå§‹è¾“å…¥
            edge_index: [2, num_edges]
            device: 'cuda' or 'cpu'

        Returns:
            encoder_features: [num_nodes, hid_dim] ç¼–ç å™¨è¾“å‡ºç‰¹å¾
        """
        full_model.eval()
        with torch.no_grad():
            num_nodes, hist_len, in_dim = input_data.shape

            # 1. ç‰¹å¾åˆ†ç¦»
            static_features = input_data[:, 0, :full_model.static_dim]
            dynamic_features = input_data[:, :, full_model.static_dim:]

            # 2. åŠ¨æ€ç¼–ç  (v2.0 å’Œ v3.0 å…±ç”¨)
            dynamic_emb = full_model.dynamic_encoder(dynamic_features)

            # 3. æ£€æµ‹æ¶æ„ç‰ˆæœ¬å¹¶è¿›è¡Œç‰¹å¾èåˆ
            if hasattr(full_model, 'static_encoder'):
                static_emb = full_model.static_encoder(static_features)
                x = full_model.fusion(static_emb, dynamic_emb)
            else:
                # v3.0: fusion(static_features, dynamic_emb)
                # CrossAttentionFusionV2.forward å†…éƒ¨è°ƒç”¨ self.static_encoder
                x = full_model.fusion(static_features, dynamic_emb)

        return x.to(device)


def create_gnn_wrapper(model, model_type=None):
    """
    å·¥å‚å‡½æ•°: æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºå¯¹åº”çš„GNNåŒ…è£…å™¨

    Args:
        model: å®Œæ•´çš„LSTM-GNNæ··åˆæ¨¡å‹
        model_type: æ¨¡å‹ç±»å‹ ('GAT_LSTM', 'GSAGE_LSTM', 'GAT_SeparateEncoder', None)
                   å¦‚æœä¸ºNone,åˆ™è‡ªåŠ¨æ£€æµ‹

    Returns:
        GATWrapper/GSAGEWrapper/GATSeparateEncoderWrapper å®ä¾‹

    Raises:
        ValueError: å¦‚æœæ¨¡å‹ç±»å‹ä¸æ”¯æŒ

    ç¤ºä¾‹:
        >>> # è‡ªåŠ¨æ£€æµ‹
        >>> wrapper = create_gnn_wrapper(model)
        >>>
        >>> # æ‰‹åŠ¨æŒ‡å®š
        >>> wrapper = create_gnn_wrapper(model, 'GAT_LSTM')
    """
    if model_type is None:
        # è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹
        from .utils import detect_model_type
        model_type = detect_model_type(model)

    if model_type == 'GAT_LSTM':
        return GATWrapper(model)
    elif model_type == 'GSAGE_LSTM':
        return GSAGEWrapper(model)
    elif model_type == 'GAT_SeparateEncoder':
        return GATSeparateEncoderWrapper(model)
    else:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}. "
            f"æ”¯æŒçš„ç±»å‹: GAT_LSTM, GSAGE_LSTM, GAT_SeparateEncoder"
        )


def verify_wrapper_consistency(full_model, wrapper, test_input, edge_index, device='cpu'):
    """
    éªŒè¯Wrapperè¾“å‡ºä¸åŸæ¨¡å‹ä¸€è‡´æ€§

    Args:
        full_model: å®Œæ•´æ¨¡å‹
        wrapper: GNNåŒ…è£…å™¨
        test_input: [num_nodes, hist_len, in_dim] æµ‹è¯•è¾“å…¥
        edge_index: [2, num_edges]
        device: 'cuda' or 'cpu'

    Returns:
        bool: æ˜¯å¦ä¸€è‡´(è¯¯å·®<1e-5)
        float: æœ€å¤§ç»å¯¹è¯¯å·®

    ç¤ºä¾‹:
        >>> is_consistent, max_error = verify_wrapper_consistency(
        >>>     model, wrapper, test_data, edge_index
        >>> )
        >>> assert is_consistent, f"ä¸ä¸€è‡´! è¯¯å·®: {max_error}"
    """
    full_model.eval()
    wrapper.eval()

    # åŸæ¨¡å‹é¢„æµ‹
    with torch.no_grad():
        pred_original = full_model(
            test_input.to(device),
            edge_index.to(device)
        )

    # Wrapperé¢„æµ‹
    # 1. æå–ç¼–ç å™¨ç‰¹å¾ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æ–¹æ³•ï¼‰
    if isinstance(wrapper, GATWrapper):
        encoder_features = GATWrapper.extract_lstm_features(
            full_model, test_input, edge_index, device
        )
    elif isinstance(wrapper, GSAGEWrapper):
        encoder_features = GSAGEWrapper.extract_lstm_features(
            full_model, test_input, edge_index, device
        )
    elif isinstance(wrapper, GATSeparateEncoderWrapper):
        encoder_features = GATSeparateEncoderWrapper.extract_encoder_features(
            full_model, test_input, edge_index, device
        )
    else:
        raise ValueError(f"æœªçŸ¥çš„wrapperç±»å‹: {type(wrapper)}")

    # 2. Wrapperå‰å‘ä¼ æ’­
    with torch.no_grad():
        pred_wrapper = wrapper(
            encoder_features.to(device),
            edge_index.to(device)
        )

    # è®¡ç®—è¯¯å·®
    max_error = (pred_original - pred_wrapper).abs().max().item()
    is_consistent = max_error < 1e-5

    return is_consistent, max_error
