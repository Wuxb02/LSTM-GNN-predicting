"""
GAT + åˆ†ç¦»å¼ç¼–ç å™¨ æ¨¡å‹ (ä¼˜åŒ–ç‰ˆ v3.0)

æ ¸å¿ƒæ”¹è¿›ï¼š
1. Cross-Attention Fusion V2: ç‰¹å¾çº§äº¤å‰æ³¨æ„åŠ›ï¼ˆåŠ¨æ€æŸ¥è¯¢å„é™æ€ç‰¹å¾ç»´åº¦ï¼‰
2. Learnable Node Embeddings: å¯å­¦ä¹ èŠ‚ç‚¹åµŒå…¥æ•è·éšå¼ç«™ç‚¹ç‰¹å¾
3. Skip Connection: GATè¾“å…¥åˆ°è¾“å‡ºçš„æ®‹å·®è¿æ¥ï¼ˆé˜²æ­¢è¿‡åº¦å¹³æ»‘ï¼‰
4. å¯è§£é‡Šæ€§å¢å¼º: æ”¯æŒæå–ç‰¹å¾çº§æ³¨æ„åŠ›æƒé‡

æ¶æ„å¯¹æ¯”ï¼š
- v1.0: åˆ†ç¦»å¼ç¼–ç å™¨(é™æ€MLP + åŠ¨æ€LSTM) â†’ ç®€å•èåˆ â†’ GAT â†’ è§£ç å™¨
- v2.0: åˆ†ç¦»å¼ç¼–ç å™¨ â†’ Cross-Attentionèåˆ â†’ GAT(+Skip) â†’ è§£ç å™¨
- v3.0: åˆ†ç¦»å¼ç¼–ç å™¨ â†’ ç‰¹å¾çº§Cross-Attention â†’ GAT(+Skip) â†’ è§£ç å™¨
        + æ³¨æ„åŠ›æƒé‡å¯è§£é‡Šæ€§

ä¼˜åŠ¿ï¼š
1. åŠ¨æ€ç‰¹å¾è‡ªé€‚åº”åœ°"æŸ¥è¯¢"æœ€ç›¸å…³çš„é™æ€åœ°ç†ä¿¡æ¯
2. ç‰¹å¾çº§æ³¨æ„åŠ›æƒé‡å¯è§£é‡Šï¼šå±•ç¤ºæ¨¡å‹å¯¹å„é™æ€ç‰¹å¾çš„å…³æ³¨ç¨‹åº¦
3. èŠ‚ç‚¹åµŒå…¥æ•è·æ•°æ®æœªè®°å½•çš„å¾®æ°”å€™æ•ˆåº”ï¼ˆå¦‚è¡—é“å³¡è°·æ•ˆåº”ï¼‰
4. æ®‹å·®è¿æ¥ä¿ç•™ç«™ç‚¹è‡ªèº«å†å²è¶‹åŠ¿ï¼Œé˜²æ­¢å›¾å·ç§¯è¿‡åº¦å¹³æ»‘

ä½œè€…: GNNæ°”æ¸©é¢„æµ‹é¡¹ç›®
æ—¥æœŸ: 2025-12
ç‰ˆæœ¬: 3.0
"""

import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv

def get_norm_layer(norm_type, dim):
    """è§„èŒƒåŒ–å±‚é€‰æ‹©"""
    if norm_type == 'BatchNorm':
        return nn.BatchNorm1d(dim)
    elif norm_type == 'LayerNorm':
        return nn.LayerNorm(dim)
    elif norm_type == 'None' or norm_type is None:
        return None
    else:
        raise ValueError(f"æœªçŸ¥çš„è§„èŒƒåŒ–ç±»å‹: {norm_type}")


def whichAF(AF):
    """æ¿€æ´»å‡½æ•°é€‰æ‹©"""
    if AF == 'PReLU':
        return nn.PReLU()
    elif AF == "LeakyReLU":
        return nn.LeakyReLU()
    elif AF == "ReLU":
        return nn.ReLU()
    elif AF == 'GELU':
        return nn.GELU()
    else:
        return nn.Identity()


class LightweightStaticEncoder(nn.Module):
    """
    è½»é‡çº§é™æ€ç‰¹å¾ç¼–ç å™¨ (ä¼˜åŒ–ç‰ˆ)

    ä¿ç•™ [N, 12, dim] çš„è¾“å‡ºç»“æ„ä»¥æ”¯æŒç‰¹å¾çº§æ³¨æ„åŠ›ï¼Œ
    ä½†ç§»é™¤ç¬¨é‡çš„ MLPï¼Œæ”¹ç”¨ "ç‰¹å¾å€¼ * å¯å­¦ä¹ åŸºå‘é‡" çš„æ–¹å¼ã€‚

    å‚æ•°é‡æä½ï¼Œæéš¾è¿‡æ‹Ÿåˆï¼Œä¸”å®Œå…¨ä¿ç•™å¯è§£é‡Šæ€§ã€‚
    """

    def __init__(self, num_features, output_dim):
        super(LightweightStaticEncoder, self).__init__()
        self.num_features = num_features
        self.output_dim = output_dim

        # å®šä¹‰åŸºå‘é‡ (Basis Vectors)
        # å½¢çŠ¶: [1, 12, output_dim]
        # è¿™é‡Œçš„æ¯ä¸€ä¸ªå‘é‡ä»£è¡¨ä¸€ç§ç‰¹å¾çš„"è¯­ä¹‰èº«ä»½"
        self.feature_embeddings = nn.Parameter(
            torch.randn(1, num_features, output_dim) * 0.02
        )


    def forward(self, x):
        """
        Args:
            x: [batch_size, num_features]  (åŸå§‹é™æ€ç‰¹å¾å€¼ï¼Œæ ‡é‡)

        Returns:
            [batch_size, num_features, output_dim] (ç‰¹å¾Tokenåºåˆ—)
        """
        batch_size = x.shape[0]

        # 1. æ‰©å±•è¾“å…¥ç»´åº¦
        # x: [batch, 12] -> [batch, 12, 1]
        x_expanded = x.unsqueeze(-1)

        # 2. å¹¿æ’­ä¹˜æ³• (Scaling)
        # å°†æ ‡é‡ç‰¹å¾å€¼ ä¹˜ä»¥ å¯¹åº”çš„ç‰¹å¾èº«ä»½å‘é‡
        # [batch, 12, 1] * [1, 12, dim] -> [batch, 12, dim]
        # å¹¿æ’­æœºåˆ¶ä¼šè‡ªåŠ¨å¤„ç†ç»´åº¦åŒ¹é…
        tokens = x_expanded * self.feature_embeddings

        return tokens

class DynamicEncoder(nn.Module):
    """
    åŠ¨æ€ç‰¹å¾ç¼–ç å™¨

    ä½¿ç”¨LSTMå¯¹åŠ¨æ€ç‰¹å¾ï¼ˆæ°”è±¡è¦ç´ ç­‰ï¼‰è¿›è¡Œæ—¶åºç¼–ç ã€‚
    """

    def __init__(self, input_dim, hidden_dim, num_layers=1,
                 dropout=0.1, bidirectional=False):
        super(DynamicEncoder, self).__init__()

        self.hidden_dim = hidden_dim
        self.bidirectional = bidirectional

        # è¾“å…¥æŠ•å½±
        self.input_proj = nn.Linear(input_dim, hidden_dim)

        # LSTMç¼–ç å™¨
        self.lstm = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=bidirectional,
            batch_first=False
        )

        # åŒå‘LSTMæŠ•å½±
        if bidirectional:
            self.output_proj = nn.Linear(hidden_dim * 2, hidden_dim)

    def forward(self, x):
        """
        Args:
            x: [num_nodes, hist_len, dynamic_dim] åŠ¨æ€ç‰¹å¾

        Returns:
            [num_nodes, hidden_dim] åŠ¨æ€åµŒå…¥ï¼ˆå–æœ€åæ—¶é—´æ­¥ï¼‰
        """
        # [num_nodes, hist_len, dynamic_dim] â†’ [hist_len, num_nodes, dynamic_dim]
        x = x.permute(1, 0, 2)

        # è¾“å…¥æŠ•å½±
        x = self.input_proj(x)  # [hist_len, num_nodes, hidden_dim]

        # LSTMç¼–ç 
        out, _ = self.lstm(x)
        # å–æœ€åæ—¶é—´æ­¥ [num_nodes, hidden_dim] æˆ– [num_nodes, 2*hidden_dim]
        out = out[-1]

        # åŒå‘æŠ•å½±
        if self.bidirectional:
            out = self.output_proj(out)

        return out


class CrossAttentionFusionV2(nn.Module):
    """
    ç‰¹å¾çº§äº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å— (v3.0 æ–°å¢)

    æ ¸å¿ƒæ”¹è¿›ï¼š
    - å°†12ä¸ªé™æ€ç‰¹å¾ä½œä¸ºç‹¬ç«‹çš„K/Våºåˆ—
    - æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: [N, num_heads, 1, 12] â†’ å¯¹æ¯ä¸ªé™æ€ç‰¹å¾çš„å…³æ³¨ç¨‹åº¦
    - æ”¯æŒæå–æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§£é‡Šæ€§åˆ†æ

    æ¶æ„ï¼š
    - Query (Q): åŠ¨æ€ç‰¹å¾ç¼–ç  [N, 1, dim]
    - Key (K) & Value (V): é™æ€ç‰¹å¾tokens [N, 12, dim]
    - è¾“å‡º: èåˆè¡¨ç¤º [N, dim] + å¯é€‰çš„æ³¨æ„åŠ›æƒé‡ [N, num_heads, 12]
    """

    def __init__(self, num_static_features, dynamic_dim, output_dim,
                 num_heads=4, dropout=0.1, use_pre_ln=True):
        """
        Args:
            num_static_features: é™æ€ç‰¹å¾æ•°é‡ï¼ˆå¦‚12ï¼‰
            dynamic_dim: åŠ¨æ€ç‰¹å¾ç»´åº¦ï¼ˆLSTMè¾“å‡ºç»´åº¦ï¼‰
            output_dim: è¾“å‡ºç»´åº¦
            num_heads: æ³¨æ„åŠ›å¤´æ•°
            dropout: Dropoutç‡
            use_pre_ln: æ˜¯å¦ä½¿ç”¨Pre-LN
        """
        super(CrossAttentionFusionV2, self).__init__()

        self.num_static_features = num_static_features
        self.output_dim = output_dim
        self.num_heads = num_heads
        self.use_pre_ln = use_pre_ln

        self.static_encoder = LightweightStaticEncoder(
            num_features=num_static_features,
            output_dim=output_dim  # ç¡®ä¿è¿™é‡Œç»´åº¦å’Œ dynamic_emb æŠ•å½±åçš„ç»´åº¦ä¸€è‡´
        )

        # åŠ¨æ€ç‰¹å¾æŠ•å½±
        self.dynamic_proj = nn.Linear(dynamic_dim, output_dim)

        # äº¤å‰æ³¨æ„åŠ›å±‚
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=output_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )

        # LayerNormå±‚
        self.ln1_q = nn.LayerNorm(output_dim)
        self.ln1_kv = nn.LayerNorm(output_dim)
        self.ln2 = nn.LayerNorm(output_dim)

        # FeedForward Network (FFN)
        self.ffn = nn.Sequential(
            nn.Linear(output_dim, output_dim * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(output_dim * 2, output_dim),
            nn.Dropout(dropout)
        )

    def forward(self, static_features, dynamic_emb, return_attention=False):
        """
        Args:
            static_features: [N, num_static_features] åŸå§‹é™æ€ç‰¹å¾ï¼ˆ12ç»´ï¼‰
            dynamic_emb: [N, dynamic_dim] åŠ¨æ€ç‰¹å¾ç¼–ç ï¼ˆLSTMè¾“å‡ºï¼‰
            return_attention: æ˜¯å¦è¿”å›æ³¨æ„åŠ›æƒé‡

        Returns:
            å¦‚æœ return_attention=False:
                [N, output_dim] èåˆåçš„è¡¨ç¤º
            å¦‚æœ return_attention=True:
                ([N, output_dim], [N, num_heads, num_static_features])
        """
        # é™æ€ç‰¹å¾ç¼–ç ä¸ºtokenåºåˆ—
        # [N, 12] â†’ [N, 12, output_dim]
        static_tokens = self.static_encoder(static_features)

        # åŠ¨æ€ç‰¹å¾æŠ•å½±
        # [N, dynamic_dim] â†’ [N, output_dim]
        dynamic_out = self.dynamic_proj(dynamic_emb)

        # æ„å»ºQ, K, V
        # Q: [N, 1, output_dim] (åŠ¨æ€ç‰¹å¾ä½œä¸ºæŸ¥è¯¢)
        # K, V: [N, 12, output_dim] (é™æ€ç‰¹å¾tokensä½œä¸ºé”®å€¼)
        q = dynamic_out.unsqueeze(1)  # [N, 1, output_dim]
        k = static_tokens              # [N, 12, output_dim]
        v = static_tokens              # [N, 12, output_dim]

        # ==================== æ³¨æ„åŠ›å— ====================
        if self.use_pre_ln:
            q_norm = self.ln1_q(q)
            k_norm = self.ln1_kv(k)
            v_norm = self.ln1_kv(v)
            attn_out, attn_weights = self.cross_attention(
                q_norm, k_norm, v_norm,
                need_weights=True,
                average_attn_weights=False  # ä¿ç•™å¤šå¤´ä¿¡æ¯
            )
            # attn_out: [N, 1, output_dim]
            # attn_weights: [N, num_heads, 1, 12]
            attn_out = attn_out.squeeze(1)  # [N, output_dim]
            x = dynamic_out + attn_out
        else:
            attn_out, attn_weights = self.cross_attention(
                q, k, v,
                need_weights=True,
                average_attn_weights=False
            )
            attn_out = attn_out.squeeze(1)
            x = dynamic_out + attn_out
            x = self.ln1_q(x)

        # ==================== FFNå— ====================
        if self.use_pre_ln:
            ffn_out = self.ffn(self.ln2(x))
            x = x + ffn_out
        else:
            ffn_out = self.ffn(x)
            x = x + ffn_out
            x = self.ln2(x)

        if return_attention:
            # attn_weights: [N, num_heads, 1, 12] â†’ [N, num_heads, 12]
            attn_weights = attn_weights.squeeze(2)
            return x, attn_weights
        else:
            return x


class GAT_SeparateEncoder(nn.Module):
    """
    GAT + åˆ†ç¦»å¼ç¼–ç å™¨ æ¨¡å‹ (ä¼˜åŒ–ç‰ˆ v3.0)

    æ¶æ„:
    1. å¯å­¦ä¹ èŠ‚ç‚¹åµŒå…¥ â­
       - æ•è·éšå¼ç«™ç‚¹ç‰¹å¾ï¼ˆå¦‚å¾®æ°”å€™ã€è¡—é“å³¡è°·æ•ˆåº”ç­‰ï¼‰
    2. åˆ†ç¦»å¼ç¼–ç å™¨:
       - åŠ¨æ€ç‰¹å¾ â†’ DynamicEncoder(LSTM) â†’ åŠ¨æ€åµŒå…¥
       - é™æ€ç‰¹å¾(12ç»´) â†’ CrossAttentionFusionV2 â†’ ç‰¹å¾çº§æ³¨æ„åŠ›èåˆ
    3. GATå›¾å·ç§¯å±‚ x N (å¸¦æ®‹å·®è¿æ¥) â­
    4. LSTMè§£ç å™¨ï¼ˆå¤šæ­¥é¢„æµ‹ï¼‰

    v3.0 æ–°ç‰¹æ€§:
    - ç‰¹å¾çº§Cross-Attention: 12ä¸ªé™æ€ç‰¹å¾ä½œä¸ºç‹¬ç«‹K/V
    - æ³¨æ„åŠ›æƒé‡å¯è§£é‡Š: å±•ç¤ºæ¨¡å‹å¯¹å„é™æ€ç‰¹å¾çš„å…³æ³¨ç¨‹åº¦
    - æ”¯æŒæå–æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–åˆ†æ

    è¾“å…¥æ ¼å¼:
    x: [num_nodes, hist_len, in_dim]
    å…¶ä¸­ in_dim = static_dim(12) + dynamic_dim(12) + temporal_dim(4)
    """

    def __init__(self, config, arch_arg):
        super(GAT_SeparateEncoder, self).__init__()

        # ä¿å­˜é…ç½®
        self.config = config

        # ä»configè·å–ç‰¹å¾åˆ†ç¦»å‚æ•°
        self.use_feature_separation = getattr(
            config, 'use_feature_separation', True
        )
        self.static_dim = getattr(config, 'static_encoded_dim', 8)
        self.dynamic_dim = len(getattr(
            config, 'dynamic_feature_indices', list(range(12))
        ))
        self.temporal_dim = (
            config.temporal_features if config.add_temporal_encoding else 0
        )

        # æ¨¡å‹å‚æ•°
        self.hid_dim = arch_arg.hid_dim
        self.nGAT_layer = arch_arg.GAT_layer
        self.heads = arch_arg.heads
        self.out_dim = config.pred_len

        AF = whichAF(arch_arg.AF)

        # ==================== ğŸ”¥ å¯å­¦ä¹ èŠ‚ç‚¹åµŒå…¥ ====================
        # æ•è·æœªè¢«æ•°æ®è®°å½•çš„éšå¼ç«™ç‚¹ç‰¹å¾ï¼ˆå¦‚å¾®æ°”å€™æ•ˆåº”ï¼‰
        self.node_emb_dim = getattr(arch_arg, 'node_emb_dim', 4)  # é»˜è®¤4ç»´

        # ==================== åˆ†ç¦»å¼ç¼–ç å™¨ ====================
        # åŠ¨æ€ç¼–ç å™¨ï¼ˆLSTMå¤„ç†æ—¶åºç‰¹å¾ï¼‰
        dynamic_input_dim = self.dynamic_dim + self.temporal_dim
        self.dynamic_encoder = DynamicEncoder(
            input_dim=dynamic_input_dim,
            hidden_dim=self.hid_dim // 2,
            num_layers=arch_arg.lstm_num_layers,
            dropout=arch_arg.lstm_dropout,
            bidirectional=arch_arg.lstm_bidirectional
        )

        # ==================== ğŸ”¥ v3.0: ç‰¹å¾çº§äº¤å‰æ³¨æ„åŠ›èåˆ ====================
        # 12ä¸ªé™æ€ç‰¹å¾ä½œä¸ºç‹¬ç«‹çš„K/Vï¼Œæ”¯æŒæå–ç‰¹å¾çº§æ³¨æ„åŠ›æƒé‡
        fusion_num_heads = getattr(arch_arg, 'fusion_num_heads', 4)
        fusion_use_pre_ln = getattr(arch_arg, 'fusion_use_pre_ln', True)

        # é™æ€ç‰¹å¾æ•°é‡ï¼ˆåŒ…å«èŠ‚ç‚¹åµŒå…¥ï¼‰
        num_static_features = self.static_dim
        self.num_static_features = num_static_features

        self.fusion = CrossAttentionFusionV2(
            num_static_features=num_static_features,
            dynamic_dim=self.hid_dim // 2,
            output_dim=self.hid_dim,
            num_heads=fusion_num_heads,
            dropout=arch_arg.inter_drop,
            use_pre_ln=fusion_use_pre_ln
        )

        # ==================== GATå±‚ ====================
        GAT_layers = []

        # è®¡ç®—æ¯ä¸ªGATå—çš„å±‚æ•°
        self.element = 3  # GAT + Linear + AF
        if arch_arg.norm_type and arch_arg.norm_type != 'None':
            self.element += 1
        if arch_arg.dropout:
            self.element += 1

        for n in range(self.nGAT_layer):
            GAT_layers.append(
                GATv2Conv(
                    self.hid_dim, self.hid_dim,
                    heads=self.heads, concat=True,
                    dropout=arch_arg.intra_drop,
                    add_self_loops=True, share_weights=False
                )
            )
            GAT_layers.append(
                nn.Linear(self.heads * self.hid_dim, self.hid_dim))
            GAT_layers.append(AF)

            norm_layer = get_norm_layer(arch_arg.norm_type, self.hid_dim)
            if norm_layer is not None:
                GAT_layers.append(norm_layer)
            if arch_arg.dropout:
                GAT_layers.append(nn.Dropout(arch_arg.inter_drop))

        self.GAT_layers = nn.ModuleList(GAT_layers)

        # ==================== ğŸ”¥ æ–°å¢2: æ®‹å·®è¿æ¥æ§åˆ¶ ====================
        # åœ¨GATè¾“å…¥ï¼ˆèåˆè¾“å‡ºï¼‰å’ŒGATè¾“å‡ºä¹‹é—´æ·»åŠ è·³è·ƒè¿æ¥
        self.use_skip_connection = getattr(
            arch_arg, 'use_skip_connection', True)

        # ==================== è§£ç å™¨ ====================
        # MLPè¾“å‡ºå±‚
        MLP_layers_out = []
        for n in range(arch_arg.MLP_layer):
            MLP_layers_out.append(nn.Linear(self.hid_dim, self.hid_dim))
            MLP_layers_out.append(AF)
        MLP_layers_out.append(nn.Linear(self.hid_dim, self.out_dim))
        self.MLP_layers_out = nn.Sequential(*MLP_layers_out)


    def forward(self, x, edge_index, edge_attr=None, return_cross_attention=False):
        """
        å‰å‘ä¼ æ’­

        Args:
            x: [batch_size * num_nodes, hist_len, in_dim] æˆ– [num_nodes, hist_len, in_dim]
               å…¶ä¸­ in_dim = static_dim + dynamic_dim + temporal_dim
               æ•°æ®æ ¼å¼: [é™æ€ç‰¹å¾(12), åŠ¨æ€ç‰¹å¾(12), æ—¶é—´ç¼–ç (4)]
            edge_index: [2, num_edges]
            edge_attr: è¾¹å±æ€§ï¼ˆå¯é€‰ï¼‰
            return_cross_attention: æ˜¯å¦è¿”å›Cross-Attentionæƒé‡ï¼ˆç”¨äºå¯è§£é‡Šæ€§åˆ†æï¼‰

        Returns:
            å¦‚æœ return_cross_attention=False:
                [batch_size * num_nodes, pred_len] é¢„æµ‹ç»“æœ
            å¦‚æœ return_cross_attention=True:
                (é¢„æµ‹ç»“æœ, Cross-Attentionæƒé‡ [N, num_heads, num_static_features])
        """
        total_nodes, hist_len, in_dim = x.shape

        # ==================== 1. ç‰¹å¾åˆ†ç¦» ====================
        # ä»ç»„åˆè¾“å…¥ä¸­åˆ†ç¦»é™æ€å’ŒåŠ¨æ€éƒ¨åˆ†
        # è¾“å…¥æ ¼å¼: [é™æ€ç‰¹å¾(12), åŠ¨æ€ç‰¹å¾(12), æ—¶é—´ç¼–ç (4)]
        # [total_nodes, static_dim]
        static_features = x[:, 0, :self.static_dim]
        # [total_nodes, hist_len, dynamic_dim+temporal_dim]
        dynamic_features = x[:, :, self.static_dim:]

        # ==================== 3. åŠ¨æ€ç¼–ç  ====================
        dynamic_emb = self.dynamic_encoder(
            dynamic_features)  # [total_nodes, hid_dim//2]

        # ==================== 4. ç‰¹å¾çº§äº¤å‰æ³¨æ„åŠ›èåˆ (v3.0) â­ ====================
        # åŠ¨æ€ç‰¹å¾ä½œä¸ºQueryï¼ŒæŸ¥è¯¢æœ€ç›¸å…³çš„é™æ€åœ°ç†ä¿¡æ¯
        # è¿”å›èåˆè¡¨ç¤º + å¯é€‰çš„ç‰¹å¾çº§æ³¨æ„åŠ›æƒé‡
        if return_cross_attention:
            fusion_out, cross_attn_weights = self.fusion(
                static_features, dynamic_emb, return_attention=True
            )
            # cross_attn_weights: [N, num_heads, num_static_features]
        else:
            fusion_out = self.fusion(
                static_features, dynamic_emb, return_attention=False)

        # ==================== 5. GATå›¾å·ç§¯ï¼ˆå¸¦æ®‹å·®è¿æ¥ï¼‰â­ ====================
        x = fusion_out  # ä¿å­˜èåˆè¾“å‡ºï¼Œç”¨äºåç»­æ®‹å·®è¿æ¥

        for i in range(self.nGAT_layer):
            base_idx = i * self.element
            x = self.GAT_layers[base_idx](x, edge_index)
            for j in range(1, self.element):
                x = self.GAT_layers[base_idx + j](x)

        # ğŸ”¥ æ–°å¢: æ®‹å·®è¿æ¥ï¼ˆé˜²æ­¢è¿‡åº¦å¹³æ»‘ï¼Œä¿ç•™ç«™ç‚¹è‡ªèº«å†å²è¶‹åŠ¿ï¼‰
        if self.use_skip_connection:
            # Element-wise Addition: GATè¾“å‡º + èåˆè¾“å‡º
            x = x + fusion_out

        # ==================== 6. è§£ç å™¨ ====================
        x = self.MLP_layers_out(x)

        # è¿”å›ç»“æœ
        if return_cross_attention:
            return x, cross_attn_weights
        else:
            return x


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 70)
    print("GAT_SeparateEncoder æ¨¡å‹æµ‹è¯• (v3.0 - ç‰¹å¾çº§æ³¨æ„åŠ›)")
    print("=" * 70)

    # æ¨¡æ‹Ÿé…ç½®
    class MockConfig:
        in_dim = 28  # 12(é™æ€) + 12(åŠ¨æ€) + 4(æ—¶é—´ç¼–ç )
        pred_len = 3
        node_num = 28
        use_feature_separation = True
        static_encoded_dim = 12  # 12ä¸ªé™æ€ç‰¹å¾
        dynamic_feature_indices = [3, 4, 5, 6, 7, 8, 9, 19, 20, 21, 22, 23]
        add_temporal_encoding = True
        temporal_features = 4

    class MockArchArg:
        hid_dim = 32
        MLP_layer = 1
        AF = 'ReLU'
        norm_type = 'LayerNorm'
        dropout = True
        GAT_layer = 2
        heads = 2
        intra_drop = 0.1
        inter_drop = 0.1
        lstm_num_layers = 1
        lstm_dropout = 0.1
        lstm_bidirectional = False
        decoder_num_layers = 1
        decoder_dropout = 0.1
        decoder_mlp_layers = 0

        # v3.0 å‚æ•°
        node_emb_dim = 4            # èŠ‚ç‚¹åµŒå…¥ç»´åº¦
        fusion_num_heads = 4        # äº¤å‰æ³¨æ„åŠ›å¤´æ•°
        fusion_use_pre_ln = True    # ä½¿ç”¨Pre-LN
        use_skip_connection = True  # å¯ç”¨æ®‹å·®è¿æ¥

    config = MockConfig()
    arch_arg = MockArchArg()

    print(f"\n{'='*50}")
    print("æµ‹è¯• v3.0 ç‰¹å¾çº§æ³¨æ„åŠ›æ¨¡å‹")
    print(f"  - é™æ€ç‰¹å¾æ•°: {config.static_encoded_dim}")
    print(f"  - äº¤å‰æ³¨æ„åŠ›: {arch_arg.fusion_num_heads} å¤´")
    print(f"  - æ®‹å·®è¿æ¥: {'å¯ç”¨' if arch_arg.use_skip_connection else 'ç¦ç”¨'}")
    print(f"{'='*50}")

    model = GAT_SeparateEncoder(config, arch_arg)
    model.eval()  # Set to evaluation mode for testing

    # æ¨¡æ‹Ÿè¾“å…¥
    batch_size = 28
    hist_len = 7
    x = torch.randn(batch_size, hist_len, config.in_dim)
    edge_index = torch.randint(0, batch_size, (2, 100))

    print(f"\nè¾“å…¥å½¢çŠ¶: {x.shape}")

    # Test 1: Normal forward pass
    print("\n[Test 1] Normal forward pass")
    out = model(x, edge_index)
    print(f"  Output shape: {out.shape}")
    print(f"  Expected shape: [{batch_size}, {config.pred_len}]")
    assert out.shape == (
        batch_size, config.pred_len), f"Shape mismatch: {out.shape}"
    print("  [OK] Shape validation passed")

    # Test 2: Forward pass with attention weights
    print("\n[Test 2] Forward pass with Cross-Attention weights")
    out, attn_weights = model(x, edge_index, return_cross_attention=True)
    print(f"  Output shape: {out.shape}")
    print(f"  Attention weights shape: {attn_weights.shape}")
    num_static_features = config.static_encoded_dim + arch_arg.node_emb_dim
    expected_attn_shape = (
        batch_size, arch_arg.fusion_num_heads, num_static_features)
    print(f"  Expected attention shape: {expected_attn_shape}")
    assert attn_weights.shape == expected_attn_shape, \
        f"Attention shape mismatch: {attn_weights.shape}"
    print("  [OK] Attention weights shape validation passed")

    # Verify attention weights are normalized (sum to 1)
    attn_sum = attn_weights[0, 0, :].sum().item()
    print(f"  Attention weights sum (should be ~1.0): {attn_sum:.4f}")
    assert abs(
        attn_sum - 1.0) < 0.01, f"Attention weights not normalized: {attn_sum}"
    print("  [OK] Attention weights normalization passed")

    # Parameter statistics
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel()
                           for p in model.parameters() if p.requires_grad)
    print(f"\nParameter Statistics:")
    print(f"  - Total parameters: {total_params:,}")
    print(f"  - Trainable parameters: {trainable_params:,}")


    # Check static features count
    print(f"  - Static features (with node emb): {model.num_static_features}")

    print("\n" + "=" * 70)
    print("All tests passed!")
    print("=" * 70)
