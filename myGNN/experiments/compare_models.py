"""
å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”è„šæœ¬

åŠŸèƒ½:
1. è¯»å–checkpointsç›®å½•ä¸‹æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒç»“æœ
2. è§£æmetrics.txtæ–‡ä»¶æå–è¯„ä¼°æŒ‡æ ‡
3. ç”Ÿæˆå¯¹æ¯”CSVæ–‡ä»¶
4. (å¯é€‰) ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨

ä½¿ç”¨æ–¹æ³•:
    python myGNN/experiments/compare_models.py

è¾“å‡º:
    - model_comparison.csv: å¯¹æ¯”ç»“æœè¡¨æ ¼
    - model_comparison.png: (å¯é€‰) å¯¹æ¯”æŸ±çŠ¶å›¾

ä½œè€…: GNNæ°”æ¸©é¢„æµ‹é¡¹ç›®
æ—¥æœŸ: 2025-12-20
"""

import os
import re
from pathlib import Path
import pandas as pd


def parse_metrics_file(metrics_path):
    """
    è§£æmetrics.txtæ–‡ä»¶ï¼Œæå–è¯„ä¼°æŒ‡æ ‡

    Args:
        metrics_path: metrics.txtæ–‡ä»¶è·¯å¾„

    Returns:
        metrics_dict: åŒ…å«RMSE, MAE, RÂ², Biasçš„å­—å…¸
                     åˆ†ä¸ºtrain/val/testä¸‰ä¸ªéƒ¨åˆ†
    """
    with open(metrics_path, 'r', encoding='utf-8') as f:
        content = f.read()

    metrics = {
        'train': {}, 'val': {}, 'test': {}
    }

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æŒ‡æ ‡
    # æ ¼å¼: "RMSE: 1.2345 Â°C"
    rmse_pattern = r'RMSE:\s+([\d.]+)\s+Â°C'
    mae_pattern = r'MAE:\s+([\d.]+)\s+Â°C'
    r2_pattern = r'RÂ²:\s+([\d.]+)'
    bias_pattern = r'Bias:\s+([+-]?[\d.]+)\s+Â°C'

    # æŒ‰æ•°æ®é›†åˆ†å‰²å†…å®¹
    sections = {
        'train': re.search(r'è®­ç»ƒé›†:.*?(?=\néªŒè¯é›†:|\næµ‹è¯•é›†:|$)', content, re.DOTALL),
        'val': re.search(r'éªŒè¯é›†:.*?(?=\næµ‹è¯•é›†:|$)', content, re.DOTALL),
        'test': re.search(r'æµ‹è¯•é›†:.*?(?=$)', content, re.DOTALL)
    }

    for dataset, match in sections.items():
        if match:
            section_text = match.group(0)

            # æå–å„é¡¹æŒ‡æ ‡
            rmse_match = re.search(rmse_pattern, section_text)
            mae_match = re.search(mae_pattern, section_text)
            r2_match = re.search(r2_pattern, section_text)
            bias_match = re.search(bias_pattern, section_text)

            if rmse_match:
                metrics[dataset]['rmse'] = float(rmse_match.group(1))
            if mae_match:
                metrics[dataset]['mae'] = float(mae_match.group(1))
            if r2_match:
                metrics[dataset]['r2'] = float(r2_match.group(1))
            if bias_match:
                metrics[dataset]['bias'] = float(bias_match.group(1))

    return metrics


def extract_model_name(checkpoint_dir):
    """
    ä»checkpointç›®å½•åæå–æ¨¡å‹åç§°

    Args:
        checkpoint_dir: checkpointç›®å½•å (å¦‚ 'GAT_LSTM_20251220_153042')

    Returns:
        model_name: æ¨¡å‹åç§° (å¦‚ 'GAT_LSTM')
    """
    # ç§»é™¤æ—¶é—´æˆ³éƒ¨åˆ†
    # æ ¼å¼: {æ¨¡å‹å}_{æ—¶é—´æˆ³}
    parts = checkpoint_dir.split('_')

    # æ‰¾åˆ°æ—¶é—´æˆ³çš„èµ·å§‹ä½ç½®ï¼ˆ8ä½æ•°å­—ï¼‰
    timestamp_idx = None
    for i, part in enumerate(parts):
        if len(part) == 8 and part.isdigit():
            timestamp_idx = i
            break

    if timestamp_idx is not None:
        # è¿”å›æ—¶é—´æˆ³ä¹‹å‰çš„æ‰€æœ‰éƒ¨åˆ†
        return '_'.join(parts[:timestamp_idx])
    else:
        # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œè¿”å›å®Œæ•´ç›®å½•å
        return checkpoint_dir


def collect_all_results(checkpoints_dir='checkpoints'):
    """
    æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒç»“æœ

    Args:
        checkpoints_dir: checkpointsç›®å½•è·¯å¾„

    Returns:
        results: List[Dict] åŒ…å«æ‰€æœ‰æ¨¡å‹ç»“æœçš„åˆ—è¡¨
    """
    checkpoints_path = Path(__file__).parent.parent / checkpoints_dir

    if not checkpoints_path.exists():
        print(f"é”™è¯¯: checkpointsç›®å½•ä¸å­˜åœ¨: {checkpoints_path}")
        return []

    results = []

    # éå†checkpointsç›®å½•
    for checkpoint_dir in sorted(checkpoints_path.iterdir()):
        if not checkpoint_dir.is_dir():
            continue

        metrics_file = checkpoint_dir / 'metrics.txt'

        if not metrics_file.exists():
            print(f"è­¦å‘Š: {checkpoint_dir.name} ä¸­æœªæ‰¾åˆ° metrics.txtï¼Œè·³è¿‡")
            continue

        # è§£ææŒ‡æ ‡
        try:
            metrics = parse_metrics_file(metrics_file)

            # æå–æ¨¡å‹åç§°
            model_name = extract_model_name(checkpoint_dir.name)

            # æ„å»ºç»“æœå­—å…¸
            result = {
                'Model': model_name,
                'Checkpoint': checkpoint_dir.name,
                # æµ‹è¯•é›†æŒ‡æ ‡
                'Test_RMSE': metrics['test'].get('rmse', None),
                'Test_MAE': metrics['test'].get('mae', None),
                'Test_R2': metrics['test'].get('r2', None),
                'Test_Bias': metrics['test'].get('bias', None),
                # éªŒè¯é›†æŒ‡æ ‡
                'Val_RMSE': metrics['val'].get('rmse', None),
                'Val_MAE': metrics['val'].get('mae', None),
                'Val_R2': metrics['val'].get('r2', None),
                'Val_Bias': metrics['val'].get('bias', None),
            }

            results.append(result)
            print(f"âœ“ è¯»å–: {checkpoint_dir.name}")

        except Exception as e:
            print(f"é”™è¯¯: è§£æ {checkpoint_dir.name} å¤±è´¥: {e}")
            continue

    return results


def generate_comparison_table(results, save_path='model_comparison.csv'):
    """
    ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼å¹¶ä¿å­˜

    Args:
        results: List[Dict] æ¨¡å‹ç»“æœåˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„

    Returns:
        df: pandas DataFrame
    """
    if not results:
        print("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„ç»“æœæ•°æ®")
        return None

    # åˆ›å»ºDataFrame
    df = pd.DataFrame(results)

    # æŒ‰æµ‹è¯•é›†RMSEæ’åº
    df = df.sort_values('Test_RMSE')

    # ä¿å­˜CSV
    save_path = Path(__file__).parent / save_path
    df.to_csv(save_path, index=False, encoding='utf-8-sig')

    print(f"\nâœ“ å¯¹æ¯”ç»“æœå·²ä¿å­˜åˆ°: {save_path}")

    return df


def print_comparison_summary(df):
    """
    æ‰“å°å¯¹æ¯”ç»“æœæ‘˜è¦

    Args:
        df: pandas DataFrame
    """
    print("\n" + "=" * 80)
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯” (æŒ‰æµ‹è¯•é›†RMSEæ’åº)")
    print("=" * 80)

    # é€‰æ‹©å…³é”®åˆ—æ˜¾ç¤º
    display_cols = ['Model', 'Test_RMSE', 'Test_MAE', 'Test_R2', 'Test_Bias']
    summary_df = df[display_cols].copy()

    # æ ¼å¼åŒ–æ˜¾ç¤º
    summary_df['Test_RMSE'] = summary_df['Test_RMSE'].map(lambda x: f"{x:.4f}")
    summary_df['Test_MAE'] = summary_df['Test_MAE'].map(lambda x: f"{x:.4f}")
    summary_df['Test_R2'] = summary_df['Test_R2'].map(lambda x: f"{x:.4f}")
    summary_df['Test_Bias'] = summary_df['Test_Bias'].map(lambda x: f"{x:+.4f}")

    print(summary_df.to_string(index=False))
    print("=" * 80)

    # æ‰“å°æœ€ä½³æ¨¡å‹
    best_model = df.iloc[0]
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹ (RMSEæœ€ä½): {best_model['Model']}")
    print(f"   æµ‹è¯•é›†RMSE: {best_model['Test_RMSE']:.4f} Â°C")
    print(f"   æµ‹è¯•é›†MAE:  {best_model['Test_MAE']:.4f} Â°C")
    print(f"   æµ‹è¯•é›†RÂ²:   {best_model['Test_R2']:.4f}")
    print(f"   æµ‹è¯•é›†Bias: {best_model['Test_Bias']:+.4f} Â°C")


def plot_comparison(df, save_path='model_comparison.png'):
    """
    ç»˜åˆ¶å¯¹æ¯”æŸ±çŠ¶å›¾

    Args:
        df: pandas DataFrame
        save_path: ä¿å­˜è·¯å¾„
    """
    try:
        import matplotlib.pyplot as plt
        import matplotlib
        matplotlib.rcParams['font.sans-serif'] = ['SimHei']
        matplotlib.rcParams['axes.unicode_minus'] = False

        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # RMSEå¯¹æ¯”
        ax1 = axes[0, 0]
        df.plot(x='Model', y='Test_RMSE', kind='bar', ax=ax1, color='steelblue', legend=False)
        ax1.set_title('æµ‹è¯•é›†RMSEå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax1.set_ylabel('RMSE (Â°C)', fontsize=12)
        ax1.set_xlabel('')
        ax1.tick_params(axis='x', rotation=45)
        ax1.grid(axis='y', alpha=0.3)

        # MAEå¯¹æ¯”
        ax2 = axes[0, 1]
        df.plot(x='Model', y='Test_MAE', kind='bar', ax=ax2, color='coral', legend=False)
        ax2.set_title('æµ‹è¯•é›†MAEå¯¹æ¯”', fontsize=14, fontweight='bold')
        ax2.set_ylabel('MAE (Â°C)', fontsize=12)
        ax2.set_xlabel('')
        ax2.tick_params(axis='x', rotation=45)
        ax2.grid(axis='y', alpha=0.3)

        # RÂ²å¯¹æ¯”
        ax3 = axes[1, 0]
        df.plot(x='Model', y='Test_R2', kind='bar', ax=ax3, color='mediumseagreen', legend=False)
        ax3.set_title('æµ‹è¯•é›†RÂ²å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax3.set_ylabel('RÂ² (å†³å®šç³»æ•°)', fontsize=12)
        ax3.set_xlabel('')
        ax3.tick_params(axis='x', rotation=45)
        ax3.grid(axis='y', alpha=0.3)

        # Biaså¯¹æ¯”
        ax4 = axes[1, 1]
        df.plot(x='Model', y='Test_Bias', kind='bar', ax=ax4, color='mediumpurple', legend=False)
        ax4.set_title('æµ‹è¯•é›†Biaså¯¹æ¯”', fontsize=14, fontweight='bold')
        ax4.set_ylabel('Bias (Â°C)', fontsize=12)
        ax4.set_xlabel('')
        ax4.tick_params(axis='x', rotation=45)
        ax4.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)
        ax4.grid(axis='y', alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        save_path = Path(__file__).parent / save_path
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ“ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")

    except ImportError:
        print("è­¦å‘Š: matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
    except Exception as e:
        print(f"è­¦å‘Š: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)

    # 1. æ”¶é›†æ‰€æœ‰ç»“æœ
    print("\n[1/3] æ”¶é›†è®­ç»ƒç»“æœ...")
    results = collect_all_results()

    if not results:
        print("\né”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒç»“æœ")
        print("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤è®­ç»ƒæ¨¡å‹:")
        print("  - python myGNN/train.py  (è®­ç»ƒGNNæ¨¡å‹)")
        print("  - python myGNN/baselines/train_xgboost.py  (è®­ç»ƒXGBoostæ¨¡å‹)")
        return

    print(f"\nâœ“ æˆåŠŸæ”¶é›† {len(results)} ä¸ªæ¨¡å‹ç»“æœ")

    # 2. ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    print("\n[2/3] ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼...")
    df = generate_comparison_table(results)

    if df is not None:
        print_comparison_summary(df)

    # 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    print("\n[3/3] ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    plot_comparison(df)

    print("\n" + "=" * 80)
    print("å¯¹æ¯”åˆ†æå®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    main()
